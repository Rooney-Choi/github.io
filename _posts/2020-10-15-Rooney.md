---
title: "반사의 신비로움"
date: 2020-10-15
categories: post9
---

오늘은 **Single-Photon Avalanche (SPAD)** 소자를 사용하는 센서에서 나타나는 **"반사의 신비로움"**에 대해 설명 드리도록 하겠습니다.

SPAD 소자는 LiDAR 센서 뿐만 아니라 최근에는 Single-Photon 3D Imaging, International Laser Raning Service (ILRS) 분야에서 장거리의 건물 또는 달을 관측하기 위해서도 사용하고 있다고 합니다.

이렇게 장거리를 촬영할 수 있는 SPAD 소자 기반의 센서는 기본적으로 아래의 그림과 같이 레이저에서 빛이 나가고 표면에 반사된 빛을 수신부에서 시간과 반사되는 강도를 측정하여 거리 및 반사강도 데이터를 생성합니다.

<p align="center"><img src="https://user-images.githubusercontent.com/69247445/96063040-01242880-0ed2-11eb-8a7a-e177e00fdf29.png"></p>

**그림 1**. Single-Photon Avalanche 센서

**참조**: *[SIGGRAPH 2020 Course] Computational Time-Resolved Imaging, Single-Photon Sensing, and Non-Line-of-Sight Imaging*

대부분의 센서들은 표면에 반사되어 들어오는 첫번째 데이터를 수신하고, 데이터를 가공하여 가시화합니다.

하지만 수신부에서 시간을 조금만 늦춰 다음 데이터를 획득하면 어떨까요?

제가 대학원생 때 자주 갔던 학회 SIGGRAPH에서는 이러한 현상을 모델링하는 연구가 처음에는 작게 Poster 또는 Paper 형태로 발표되다가 최근에는 Course 형태로 하나의 세션이 만들어져서 발표가 되고 있습니다.

아래 그림에서 보시면 센서에서 빛이 나가고, 벽에 반사되어 처음으로 들어오는 빛(1st bounce)이 일반적으로 센서들에서 획득하고 있는 데이터이고, 
벽에 반사된 빛이 또다른 객체의 표면에 반사되고, 다시 벽에 반사되어 수신분에 들어오는 빛(3rd bounce)을 수신부에서 데이터를 받을 수도 있습니다.

<p align="center"><img src="https://user-images.githubusercontent.com/69247445/96067338-84467e00-0ed4-11eb-9e8b-605699b038c3.gif"></p>

**그림 2**. Single-Photon Avalanche 센서의 다중 반사 수신

**참조**: *[SIGGRAPH 2020 Course] Computational Time-Resolved Imaging, Single-Photon Sensing, and Non-Line-of-Sight Imaging*

이렇게 받은 데이터를 모델링하게 되면 아래와 같은 결과물을 만들 수 있습니다.
위의 그림과 같이 센서와 촬영할 대상 사이를 가리고 센서에서는 벽에 반사된 빛을 통해 데이터를 획득합니다.
아래 그림 3은 촬영할 대상을 나타내고, 그림 4는 획득된 데이터를 통해 모델링한 결과물입니다.
모델링 된 결과물을 보시면 대략적인 형상들이 복원되는 것을 확인할 수 있고, 또한 촬영되는 대상들의 재질 또는 색상에 따라 반사강도 값이 달라지는 것들을 확인할 수 있습니다.

<p align="center"><img src="https://user-images.githubusercontent.com/69247445/96077536-080b6500-0eeb-11eb-9737-840392afafd7.png"></p>

**그림 3**. [Lindell et al. 2019] Wave-based non-line-of-sight imaging using fast F-K Migration - 촬영 환경

**참조**: *<http://www.computationalimaging.org/publications/nlos-fk/>*

<p align="center"><img src="https://user-images.githubusercontent.com/69247445/96077476-e01c0180-0eea-11eb-8cf7-952834a1bc6d.gif"></p>

**그림 4**. [Lindell et al. 2019] Wave-based non-line-of-sight imaging using fast F-K Migration - 모델링 결과물

**참조**: *<http://www.computationalimaging.org/publications/nlos-fk/>*

아래 영상은 위 결과물에 대한 모델링 방법과 데모 영상입니다. 참고하시기 바랍니다.

<style>.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }</style><div class='embed-container'><iframe src='https://www.youtube.com/embed/BVYfzLXUi48' frameborder='0' allowfullscreen></iframe></div>

**동영상 1**. [Lindell et al. 2019] Wave-based non-line-of-sight imaging using fast F-K Migration

**참조**: *<https://www.youtube.com/watch?v=BVYfzLXUi48>*

이러한 모델링이 가능하면 어떤 객체(자동차, 건물 벽)에 의해 가려진 부분들에 대해서 어떠한 형상이 어떻게 배치되어 있다라는 대략적인 복원이 가능하므로 유용한 어플리케이션이 나올 수 있다고 생각합니다.

LiDAR 센서는 데이터로써 현재 3차원 점 군 (거리정보), 반사강도 값을 획득하고 있지만 이러한 모델링 방법을 적용하여 추가적인 정보가 나온다면 센서를 보다 유용하게 쓸 수 있을 것이라 생각합니다.

최근, 이러한 연구 분야가 활성화 되고 있고, TOF 전문가들과 그래픽스 연구자들이 협업해서 좋은 결과물들을 만들고 있으므로 기대하셔도 좋을 것 같습니다.

오늘도 글 읽어주셔서 감사합니다 :)

> **한 줄 요약:** **N차 반사의 신비로움**: N값에 따라 바뀌는 데이터

<script id="dsq-count-scr" src="//rooney-choi.disqus.com/count.js" async></script>
