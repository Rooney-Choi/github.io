---
title: "용어 정리"
date: 2020-09-14
categories: post7
---

블로그에 방문하시는 분들, 그리고 글 읽어주시고 피드백 주시는 분들 모두 감사드립니다.

피드백 중에서 **"반사강도 게시글에서 몇 가지(캘리브레이션, 데이터)에 대해 용어 정리 부탁 드립니다"**라는 피드백에 있어
오늘은 앞의 게시글에서 간단하게 짚고 넘어갔던 캘리브레이션에 대한 내용, LiDAR에서 획득되는 데이터에 대한 용어를 설명드리겠습니다. :)

**Hardware & Acquired Data**
- **캘리브레이션 (Calibration)**

캘리브레이션 (Calibration)은 다양한 분야에서 사용하는 용어로써, 일반적으로는 측정기기의 측정 값의 오차 범위를 최소화하기 위해 교정/보정하는 과정으로
많이 사용됩니다. 하드웨어/소프트웨어의 성능 또는 주변 환경에 의해 측정되는 값이 달라질 수 있기 때문에 시스템을 설치하거나 주변 환경이 변하는 환경에 대해서는
캘리브레이션 과정을 반드시 수행함으로써 오차 범위를 최소화해주는 과정을 수행해야 합니다.

블로그 게시글에서의 캘리브레이션은 주로 카메라 캘리브레이션과 라이다-카메라 켈리브레이션을 많이 다루고 있고, 추후 다룰 예정입니다.
여기에서, 카메라 캘리브레이션은 카메라 파라미터를 구하는 과정을 뜻합니다.
3차원의 현실 공간을 카메라를 통해 2차원의 이미지로 정확하게 변환하기 위해서는
카메라에서 렌즈와 이미지 센서(CCD, CMOS)의 거리 및 각도와 같은 내부적인 요인들을 보정해줘야 하고,
이에 상응하는 초점거리(focal length), 주점(principal point) 등의 파라미터를 구하는 과정을 카메라 캘리브레이션이라고 합니다.

<p align="center"><img src="https://user-images.githubusercontent.com/69247445/93039460-8671ae80-f682-11ea-9cae-ad4bc030deba.png"></p>

**그림 1**. 카메라 캘리브레이션

**참조**: *<http://augmentmy.world/android-camera-calibration>*

라이다-카메라 캘리브레이션은 아래 그림과 같이 라이다와 카메라의 위치 관계(거리, 각도)를 정의할 수 있는 회전, 이동 행렬을 구하는 과정을 뜻합니다.
라이다와 카메라 사이의 위치 관계를 알고 있다면 카메라에서 보는 시점과 라이다에서 보는 시점을 맞출 수 있으므로, 
획득되는 카메라의 이미지와 라이다의 3차원 데이터를 동일한 시점에서 획득할 수 있습니다.
이렇게 되면 카메라의 RGB 데이터를 3차원 데이터에 맵핑할 수도 있고, 카메라에서 계산한 값을 LiDAR에 반영할수도 있고, LiDAR에서 계산한 값을 카메라에 반영할 수도 있습니다.
첫번째 게시글에서 반사강도 맵을 이용하면 라이다-카메라 캘리브레이션 과정 없이 라이다 센서만을 통해서 카메라에서 수행해왔던 수많은 어플리케이션들을 
적용할 수 있다는 것을 말씀드렸었습니다.

<p align="center"><img src="https://user-images.githubusercontent.com/69247445/93039732-3515ef00-f683-11ea-9bd5-5a8d173e2bfb.jpg"></p>

**그림 2**. 라이다-카메라 캘리브레이션

**참조**: *[Vasconcelos et al. 2012] A Minimal Solution for the Extrinsic Calibration of a Camera and a Laser-Rangefinder*

- **2차원 이미지 (2D Image)**

앞선 글들에서 카메라에서 획득되는 2차원 이미지에 대해서 말씀드린적이 있습니다.
여기에서, 2차원 이미지는 2차원 평면에 R,G,B 형태로 색상 정보가 저장되어 있는 형태를 나타내는 것을 뜻합니다.
앞서 언급드린 3차원의 현실 공간을 카메라를 통해 카메라의 2차원 평면에 RGB 또는 gray 형태로 저장되면 2차원 이미지가 됩니다.
최근, 3차원 이미지라는 용어를 쓰면서 2차원 이미지와 3차원 이미지가 어떤 차이점이 있는지에 대해 궁금한 분들이 많은 듯합니다.
3차원 이미지는 쓰는 분야에 따라 다르게 정의되기 때문에 제가 주로 있는 컴퓨터 비전/그래픽스 분야에서 제가 정의를 내리자면
2차원 이미지에서는 RGB 또는 gray 형태로 저장된다면, 3차원 이미지에서는 깊이 정보를 줄 수 있는 정보의 형태가 추가적으로 있는 것이라고 생각합니다.
3차원 이미지를 검색하면, 스테레오스코픽(Stereoscopic) 이미지와 깊이(Depth) 이미지 등이 나옵니다.
스테레오스코픽 이미지는 영화관에서 많이 볼 수 있는데, 이는 양안시차를 이용해 3D 영상/입체감을 만들 수 있는 이미지/영상을 뜻합니다. 
깊이 이미지는 카메라 평면을 기준으로 거리를 알 수 있는 z 값이 추가적으로 저장된 형태입니다.
두 이미지 모두 깊이 정보를 줄 수 있는 정보가 포함되어 있음을 알 수 있습니다.

**그림 3**. 2차원 RGB 이미지 vs 3차원 깊이 이미지

<p align="center"><img src="https://user-images.githubusercontent.com/69247445/93045334-dc9a1e00-f691-11ea-8912-473192401877.gif"></p>

**참조**: *<https://rgbd-dataset.cs.washington.edu/>*

- **3차원 점 군 (3D Point Cloud)**

마찬가지로 앞선 글들에서 3차원 점 군에 대한 이야기를 많이 했습니다.
3차원 점 군이라고 하면 모르는 분들이 많지만 3D Point Cloud라고 하면 이해하시는 분들이 많았습니다.
제가 작성한 또는 작성할 게시물에서 3차원 점 군은 3D Point Cloud의 한국말이라고 이해하시면 되고,
이는 LiDAR에서 근처 객체의 표면에 대해 획득하는 수 많은 (x,y,z) 형태의 데이터를 뜻합니다. 

**그림 4**. 3차원 점 군

<p align="center"><img src="https://user-images.githubusercontent.com/69247445/93045704-d8223500-f692-11ea-9e7a-6bac66d39292.png"></p>

**참조**: *<https://en.wikipedia.org/wiki/Point_cloud>*

오늘은 앞의 글들에서 다뤘던 중요 용어들을 간단히 설명드렸습니다.
추후 글들에서 제가 다룰 중요한 용어들 또는 게시글을 읽고 이런 부분들이 이해가 잘 안된다라고 하는 것들을 댓글 또는 메시지로 남겨주시면
답변과 함께 게시글에 업데이트 하도록 하겠습니다. 감사합니다 :)

> **한 줄 요약:** **용어 정리**: 용어 정리 게시글을 보시면 반사강도 글에 대한 이해가 더욱 쉬워집니다! :)

<script id="dsq-count-scr" src="//rooney-choi.disqus.com/count.js" async></script>
